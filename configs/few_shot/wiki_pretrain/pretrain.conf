train_path = datasets/pretrain/wiki_50000_80_first_pretrain.jsonl
valid_path = datasets/pretrain/wiki_50000_80_first_dev.json
save_path = data/pretrain/
save_path_include_iteration = True
init_eval = True
save_optimizer = False
train_log_iter = 1
final_eval = False
train_batch_size = 16
epochs = 5
lr = 2e-05
stage_one_lr_scale = 1.0
lr_warmup = 0.1
weight_decay = 0.1
max_grad_norm = 1.0
match_solver = hungarian
type_loss = celoss
match_warmup_epoch = 0
nil_weight = -1.0
match_boundary_weight = 2.0
match_class_weight = 2.0
loss_boundary_weight = 2.0
loss_class_weight = 2.0
deeply_weight = linear
use_masked_lm = False
repeat_gt_entities = -1
split_epoch = 0
local_rank = 0
world_size = 4
types_path = datasets/pretrain/wiki_50000_80_first_types.json
tokenizer_path = bert-large-cased
lowercase = False
sampling_processes = 4
label = wiki_train
log_path = data/pretrain/
store_predictions = False
store_examples = False
example_count = None
debug = False
device_id = 3
model_path = bert-large-cased
model_type = prompt4ner
cpu = False
eval_batch_size = 24
prop_drop = 0.5
freeze_transformer = True
no_overlapping = False
no_partial_overlapping = False
no_duplicate = True
cls_threshold = 0.0
boundary_threshold = 0.0
lstm_layers = 3
decoder_layers = 3
pool_type = max
prompt_number = 50
prompt_type = soft
prompt_length = 2
prompt_individual_attention = False
sentence_individual_attention = True
last_layer_for_loss = 1
withimage = False
seed = 47
cache_path = None